{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 258.73422,
      "end_time": "2021-03-15T12:15:12.666880",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-03-15T12:10:53.932660",
      "version": "2.1.0"
    },
    "colab": {
      "name": "neural_network_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEfLulM_qP91"
      },
      "source": [
        "# **Hand written digets classification using neural network MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-03-15T12:10:58.733671Z",
          "iopub.status.busy": "2021-03-15T12:10:58.732888Z",
          "iopub.status.idle": "2021-03-15T12:10:58.738500Z",
          "shell.execute_reply": "2021-03-15T12:10:58.737717Z"
        },
        "papermill": {
          "duration": 0.016847,
          "end_time": "2021-03-15T12:10:58.738674",
          "exception": false,
          "start_time": "2021-03-15T12:10:58.721827",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmepcCl7dZCF",
        "outputId": "83cd9772-c333-42e6-a303-1575b4d8b5e8"
      },
      "source": [
        "\n",
        "import numpy as np, sys # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # Plotting \n",
        "\n",
        "from google.colab import drive,files\n",
        "import os\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "#Mount Gdrive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLjb_A438oMJ"
      },
      "source": [
        "##**What we gonna build**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIZq0HN3EZa1"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1OS6SyupEWIvqyaouIre6-Q2sLQgsu9hf \"Logo Title Text 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syzqfshlqkyc"
      },
      "source": [
        "## **Load our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgmq6FVrqtfd",
        "outputId": "9f807f3a-f427-46a1-91c7-efac3c2e0ac1"
      },
      "source": [
        "trainData = pd.read_csv(\"/content/drive/MyDrive/Machine learning Workshop/code/digit-recognizer/train.csv\")\n",
        "print('The train dataset have',trainData.shape[0],'images.')\n",
        "print('There are',trainData.shape[1],'columns. 784 for pixels of each images and 1 for label field.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train dataset have 42000 images.\n",
            "There are 785 columns. 784 for pixels of each images and 1 for label field.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJFrdJV1rJNM"
      },
      "source": [
        "**Split the data into Training and testing set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsDMMFGprPIX",
        "outputId": "7aa1bf86-78cf-4634-91fc-497ed963d8a9"
      },
      "source": [
        "# We split the data to two sets one we train the model and the other set is gonna be used to test the performace of the model   \n",
        "\n",
        "# Train dataset:\n",
        "# X-Axis : Pixels values - each images 28x28 pixels convert into to  28^2 = 784 array. \n",
        "x_train = (trainData.iloc[:,1:]).values.astype('float32')\n",
        "# Y-Axis : Target : Label\n",
        "y_train = trainData.iloc[:,0].values.astype('int32')\n",
        "trainData.head()\n",
        "\n",
        "testData = pd.read_csv(\"/content/drive/MyDrive/Machine learning Workshop/code/digit-recognizer/test.csv\")\n",
        "print('The test dataset have',testData.shape[0],'images.')\n",
        "print('There are',testData.shape[1],'columns. 784 for pixels of each images without label.')\n",
        "\n",
        "# X-Axis : Pixels values\n",
        "x_test = (testData.iloc[:,0:]).values.astype('float32')\n",
        "y_test = trainData.iloc[:,0].values.astype('int32')\n",
        "\n",
        "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test dataset have 28000 images.\n",
            "There are 784 columns. 784 for pixels of each images without label.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqYuqViGq3Vg"
      },
      "source": [
        "**Plot the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WtCudVa8q5iq",
        "outputId": "8a5f039e-e7f4-4064-d358-9760c28f1f4b"
      },
      "source": [
        "#Not a necessary step, but it`s nice to visualize the data and do a sanity-check\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "j=0\n",
        "for i in range(1,43):\n",
        "    if(y_train[i] == 4):\n",
        "      j+=1\n",
        "      plt.subplot(5,5,j+1) \n",
        "      plt.imshow(x_train[i].reshape(28,28),cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x1800 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGmDkAWHvwFa"
      },
      "source": [
        "**Apply one hot encoding to our label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-03-15T12:10:58.784367Z",
          "iopub.status.busy": "2021-03-15T12:10:58.779068Z",
          "iopub.status.idle": "2021-03-15T12:11:05.179220Z",
          "shell.execute_reply": "2021-03-15T12:11:05.179731Z"
        },
        "papermill": {
          "duration": 6.41552,
          "end_time": "2021-03-15T12:11:05.179883",
          "exception": false,
          "start_time": "2021-03-15T12:10:58.764363",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c7drWqdZCL",
        "outputId": "6f858202-1af6-4b8e-ebda-090e5d8e02c8"
      },
      "source": [
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "print(\"labels after encoding then\",labels)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels after encoding then [[0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIavT8SQxVMC"
      },
      "source": [
        "## **Time to build the model**\n",
        " \n",
        " **We start by defining our activation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM2SVT-zxne8"
      },
      "source": [
        "def relu(x):\n",
        "    return (x >= 0) * x # returns x if x > 0\n",
        "\n",
        "def relu_prime(output):\n",
        "    return output >= 0 # returns 1 for input > 0\n",
        "\n",
        "def dropout(layer_shape):\n",
        "  return np.random.randint(2,size=layer_shape) * 2.\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return x*(1-x)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLYVn-7HtgBL"
      },
      "source": [
        "**Sigmoid**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1qcc8QuTdbTOBDkB0PBeHP7dodvCGmwzJ \"Logo Title Text 1\")\n",
        "\n",
        "\n",
        "\n",
        "**Relu (Rectified linear unit)**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1TjWLMp_W8tarrf5ESs_ukI_kOA-7GgSE \"Logo Title Text 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls_iKdWjyQvm"
      },
      "source": [
        "**Now we define our hyper parameters (neurons ,layer, learning rate, iterations)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdPGWoodyi-9"
      },
      "source": [
        "input_neurons = 784   # number of features Features  Aka number of input neurons\n",
        "hidden_neurons = 100   # number of hidden neurons in our  hidden layer \n",
        "output_neruons = 10   # number of labels Aka output neurons \n",
        "\n",
        "alpha =   0.001       # Learning rate \n",
        "iterations = 100      # Iterations of training \n",
        "batch_size = 100      # Batch size "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtFO86xxVmUq"
      },
      "source": [
        "**Define the model structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unrmH4WTVkop"
      },
      "source": [
        "def predict(image,weights_0_1,weights_1_2):\n",
        "  layer_input = image\n",
        "  layer_1 = relu(np.dot(layer_input,weights_0_1))\n",
        "  layer_output = np.dot(layer_1, weights_1_2)\n",
        "  return sigmoid(layer_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEm3zh6Ez9kG"
      },
      "source": [
        "**Define our objective function (What our model should do)**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1GqJUzZCthmE_S_YKs2LlMRjmY-NAF8oU \"Logo Title Text 1\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYEJm3T71MPh"
      },
      "source": [
        "def calculate_loss_mse(output,labels,batch_start,batch_end):\n",
        "  return np.sum((labels[batch_start:batch_end] - output) ** 2)\n",
        "\n",
        "def calculate_loss_cross_entropy(output,labels,batch_start,batch_end):\n",
        "  return -np.mean ( labels[batch_start:batch_end] * np.log(output) )  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1C3TBzr1l-d"
      },
      "source": [
        "**Intialize our weights Input->Hidden->output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAYRsrQ11sjS",
        "outputId": "f1131574-3e05-424e-b509-e238d693802f"
      },
      "source": [
        "weights_0_1 = 0.2*np.random.random((input_neurons,hidden_neurons)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_neurons,output_neruons)) - 0.1\n",
        "\n",
        "print(weights_0_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.08441099 -0.09170484 -0.08538625 ... -0.02718288  0.06342648\n",
            "  -0.05774966]\n",
            " [ 0.02666757 -0.09446612  0.03621382 ...  0.08782865 -0.09459027\n",
            "  -0.04844149]\n",
            " [ 0.09050405 -0.08677766 -0.00283244 ... -0.01034597  0.05011291\n",
            "   0.09978573]\n",
            " ...\n",
            " [ 0.06295794  0.0151753  -0.01057168 ...  0.00183041  0.01454868\n",
            "  -0.0158667 ]\n",
            " [ 0.05043661  0.05067888  0.02238348 ... -0.04139981  0.06732178\n",
            "  -0.0654162 ]\n",
            " [-0.09449541 -0.06136433  0.02533449 ...  0.05486884  0.08148926\n",
            "  -0.04240427]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbJu8LQWhoMk"
      },
      "source": [
        "**Test with random weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "D9b8fOLxhrJH",
        "outputId": "a6fe50c1-a399-44a3-9479-4c08f8ca1325"
      },
      "source": [
        "plt.imshow(images[25].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNm3mczMhvC6",
        "outputId": "543d6507-7c56-4ec1-f632-daaba549386f"
      },
      "source": [
        "print(\"predicted label: \",np.argmax(predict(images[25],weights_0_1,weights_1_2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sl4oIyr8EDu"
      },
      "source": [
        "### **Let's train the Neural network !!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-03-15T12:11:05.194623Z",
          "iopub.status.busy": "2021-03-15T12:11:05.193916Z",
          "iopub.status.idle": "2021-03-15T12:15:12.543081Z",
          "shell.execute_reply": "2021-03-15T12:15:12.542282Z"
        },
        "papermill": {
          "duration": 247.357732,
          "end_time": "2021-03-15T12:15:12.543218",
          "exception": false,
          "start_time": "2021-03-15T12:11:05.185486",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxqATXutdZCM",
        "outputId": "8a26bdc4-9b9a-4204-a48f-c0bb03d54522"
      },
      "source": [
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size),((i+1)*batch_size))\n",
        "\n",
        "        # feed forward\n",
        "        layer_input = images[batch_start:batch_end]\n",
        "        layer_1 = relu(np.dot(layer_input,weights_0_1))\n",
        "        dropout_mask = dropout(layer_1.shape) \n",
        "        layer_1 *=  dropout_mask   # Dropout\n",
        "        layer_output = sigmoid(np.dot(layer_1,weights_1_2))\n",
        "\n",
        "        # loss\n",
        "        error += calculate_loss_cross_entropy(layer_output,labels,batch_start,batch_end)\n",
        "\n",
        "        # back propagation\n",
        "        for k in range(batch_size):\n",
        "            # acurraccy of the model during the traing \n",
        "            correct_cnt += int(np.argmax(layer_output[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
        "          \n",
        "            # calculate our derivatives \n",
        "            layer_output_delta = sigmoid_prime((labels[batch_start:batch_end]-layer_output)/batch_size)\n",
        "\n",
        "            #print(layer_output_delta)\n",
        "            layer_1_delta = layer_output_delta.dot(weights_1_2.T) * relu_prime(layer_1)\n",
        "            layer_1_delta *= dropout_mask # Dropout\n",
        "\n",
        "            # update our weights \n",
        "            weights_1_2 = weights_1_2 + alpha * layer_1.T.dot(layer_output_delta)\n",
        "            weights_0_1 = weights_0_1 + alpha * layer_input.T.dot(layer_1_delta)\n",
        "            \n",
        "    if(j%10 == 0):\n",
        "\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "                         \"I:\" + str(j) + \\\n",
        "                         \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "                         \" Train-Acc:\" + str(correct_cnt/ float(len(images))))\n",
        "        \n",
        "print(weights_0_1)\n",
        "print(weights_1_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Train-Err:0.001 Train-Acc:0.155\n",
            "I:10 Train-Err:0.000 Train-Acc:0.766\n",
            "I:20 Train-Err:0.000 Train-Acc:0.817\n",
            "I:30 Train-Err:0.000 Train-Acc:0.864\n",
            "I:40 Train-Err:0.000 Train-Acc:0.883\n",
            "I:50 Train-Err:0.000 Train-Acc:0.882\n",
            "I:60 Train-Err:0.000 Train-Acc:0.873\n",
            "I:70 Train-Err:0.000 Train-Acc:0.891\n",
            "I:80 Train-Err:0.000 Train-Acc:0.899\n",
            "I:90 Train-Err:0.000 Train-Acc:0.908[[-0.08441099 -0.09170484 -0.08538625 ... -0.02718288  0.06342648\n",
            "  -0.05774966]\n",
            " [ 0.02666757 -0.09446612  0.03621382 ...  0.08782865 -0.09459027\n",
            "  -0.04844149]\n",
            " [ 0.09050405 -0.08677766 -0.00283244 ... -0.01034597  0.05011291\n",
            "   0.09978573]\n",
            " ...\n",
            " [ 0.06295794  0.0151753  -0.01057168 ...  0.00183041  0.01454868\n",
            "  -0.0158667 ]\n",
            " [ 0.05043661  0.05067888  0.02238348 ... -0.04139981  0.06732178\n",
            "  -0.0654162 ]\n",
            " [-0.09449541 -0.06136433  0.02533449 ...  0.05486884  0.08148926\n",
            "  -0.04240427]]\n",
            "[[ 1.27488241e-01 -5.38942474e-01 -4.28126620e-01 -5.66828678e-01\n",
            "   1.88430528e-01 -1.68943476e-01  8.85396837e-02 -5.88613163e-01\n",
            "  -3.08838708e-01 -3.04506442e-01]\n",
            " [ 1.08483866e-01 -2.34317356e-01  1.32906823e-01 -1.88504152e-01\n",
            "  -3.38919818e-01 -5.35437299e-01  4.49945858e-02 -4.50552235e-01\n",
            "  -4.03313618e-01  1.50407499e-01]\n",
            " [-5.58058766e-01  5.27244490e-02  2.75645997e-02  3.57883944e-02\n",
            "  -3.71080793e-01 -4.82319598e-01  4.47609590e-02 -1.76796911e-03\n",
            "  -4.79528382e-01 -4.79486207e-01]\n",
            " [ 6.04544349e-02 -8.27412793e-03  2.61409165e-03 -4.01807650e-02\n",
            "   8.36457078e-02  6.03861435e-02  3.59680972e-02  3.92060043e-03\n",
            "   4.84738408e-02  8.70666538e-02]\n",
            " [-4.54543866e-01 -2.40597943e-01 -5.86220529e-01 -4.23878511e-01\n",
            "   2.44114667e-01 -1.16835077e-01  1.15356898e-01 -5.09542345e-01\n",
            "  -5.86764801e-01 -1.06628114e-01]\n",
            " [ 6.81212053e-02  5.16174941e-02  7.36830806e-02  1.38272508e-02\n",
            "  -7.05696446e-03 -2.17399771e-02  7.79492731e-02  2.87928617e-02\n",
            "  -1.12098141e-02  1.51903686e-02]\n",
            " [ 2.46104771e-01 -2.57212169e-01 -4.45825458e-01 -3.10381851e-01\n",
            "  -4.78977706e-02 -2.82179836e-01  3.57181742e-02  6.58350901e-02\n",
            "  -4.47741555e-01 -3.73982633e-01]\n",
            " [-2.30178591e-01 -7.51789011e-02 -5.95326114e-01 -5.67541418e-01\n",
            "  -2.81829306e-03  9.43937808e-02  1.07878867e-01 -3.46461681e-01\n",
            "   8.24360662e-02 -5.58392558e-01]\n",
            " [-5.45486097e-01  4.22015345e-02 -4.58291250e-01  9.92850824e-02\n",
            "  -2.40651392e-01  2.48913014e-01 -1.64622059e-01 -4.16407170e-01\n",
            "  -4.57860636e-01 -1.06750608e-01]\n",
            " [-5.18345191e-01  5.96113349e-02 -3.18615028e-02 -4.46578155e-01\n",
            "  -1.21390374e-01 -3.74462569e-01  1.71535701e-01  2.99374206e-02\n",
            "  -5.22962963e-01 -3.86217590e-01]\n",
            " [-5.88700930e-01  6.14881061e-02  1.47625264e-01  1.23354221e-01\n",
            "  -5.20859159e-01 -4.18776762e-01 -4.87596763e-01  1.86839421e-02\n",
            "  -5.05204250e-01 -5.82922000e-01]\n",
            " [-6.05339357e-01 -6.80365068e-02  4.39136801e-03 -4.31487133e-01\n",
            "  -6.10193557e-02 -6.51490302e-02  1.15741941e-01 -3.68747662e-01\n",
            "  -5.87989708e-02 -7.24065285e-01]\n",
            " [-2.98252445e-01  2.34737427e-01 -4.94437211e-01  4.88876543e-01\n",
            "  -2.89636042e-01 -4.55178243e-01 -1.55851247e-01 -1.35441235e-01\n",
            "  -4.15679043e-01 -2.73028110e-01]\n",
            " [-5.50682984e-01  1.82787317e-01 -5.53372741e-02 -2.06780344e-01\n",
            "  -4.15752324e-01 -4.29169936e-02  2.16411575e-01 -5.68882881e-01\n",
            "  -4.35867706e-01  1.67706829e-01]\n",
            " [-1.13553930e-01 -2.65293075e-01 -2.82089212e-01 -2.69382885e-01\n",
            "   1.66744861e-01 -2.19252667e-01 -3.41789884e-01  4.79380321e-01\n",
            "  -3.28867929e-01 -4.44573679e-01]\n",
            " [-5.20940409e-01  6.22284541e-02 -7.32266660e-01 -4.92997837e-01\n",
            "  -3.38557182e-02 -3.86629333e-01 -6.29544958e-01 -5.30669023e-03\n",
            "  -3.88677054e-01  1.08211313e-01]\n",
            " [ 3.74257663e-02 -4.67893588e-01 -6.52392551e-01 -1.42229746e-02\n",
            "   1.50634382e-02  8.81001747e-02 -6.37310158e-02 -6.42047778e-01\n",
            "  -1.62705564e-01 -3.80387959e-01]\n",
            " [-2.03962148e-01 -5.46004402e-01 -3.64960104e-01  1.25527766e-01\n",
            "  -5.14985824e-01  9.31113450e-02 -5.80691489e-01  1.75684443e-02\n",
            "  -6.43452901e-02 -2.55571692e-02]\n",
            " [-2.14855387e-01 -5.52972534e-02 -8.25047853e-02 -2.39965196e-01\n",
            "  -1.73602530e-01 -7.38967282e-03  1.83116149e-01 -4.32529542e-01\n",
            "  -4.30140044e-01 -5.15761086e-01]\n",
            " [ 8.81718889e-02 -3.47425795e-01  7.10531409e-03  2.84976442e-02\n",
            "  -4.73622150e-01 -4.94013667e-01 -5.59628534e-01  1.26614720e-01\n",
            "  -5.88051881e-01 -3.10168733e-01]\n",
            " [-9.43606593e-02 -1.79200196e-02 -7.33425616e-02  1.00990884e-01\n",
            "  -2.88852938e-02 -2.80958868e-03  9.50952650e-02  7.75047929e-02\n",
            "   3.84587744e-02 -4.24288462e-02]\n",
            " [ 2.77004078e-02 -5.24992848e-01 -4.46659633e-02 -2.25038108e-01\n",
            "  -4.81944147e-02 -1.06424697e-02  3.50000209e-02 -3.16143670e-01\n",
            "  -1.11970378e-01 -1.75776341e-01]\n",
            " [-2.28845768e-02 -2.34551201e-01 -1.04269568e-02 -3.62313658e-01\n",
            "  -5.93272975e-01  5.05391602e-02  4.02957599e-02 -6.00950933e-01\n",
            "   6.77487501e-02 -4.20433193e-01]\n",
            " [-4.36265727e-02 -4.99028895e-02 -3.46433648e-02  6.40167800e-02\n",
            "   7.64813811e-02  9.40415213e-02  4.70556752e-02  3.70616381e-02\n",
            "  -2.76421384e-02  1.45559334e-02]\n",
            " [-1.85791071e-01 -3.58452130e-01  4.01504253e-01  3.29621534e-03\n",
            "  -3.81756752e-01 -4.16190980e-01 -4.28317271e-01  1.66773203e-02\n",
            "  -4.15375923e-01 -3.09688270e-01]\n",
            " [-4.95334731e-01  2.70707011e-02 -2.55321985e-02 -1.45724253e-03\n",
            "  -5.50402976e-01 -2.42666661e-01 -1.80043091e-01 -2.51749826e-01\n",
            "   1.27196012e-01  9.51439431e-02]\n",
            " [-5.55011214e-02  5.97612864e-03  3.04462290e-02  4.28546645e-02\n",
            "   7.29119712e-02  1.79837605e-02  2.89141699e-02  4.60292957e-02\n",
            "   3.99785472e-02 -1.00053714e-01]\n",
            " [ 9.47380056e-03  7.82078127e-02 -3.27009876e-02  9.40748847e-02\n",
            "   8.55944546e-02  1.21833582e-02  8.58814520e-02  6.67394434e-02\n",
            "  -3.62427574e-02  8.35606584e-02]\n",
            " [-9.46924627e-02 -1.18046760e-01 -1.48018285e-01 -1.16665147e-01\n",
            "   6.48311761e-01 -1.22281506e-01 -3.44797710e-01 -2.07964941e-01\n",
            "  -2.03392199e-01 -2.72122736e-01]\n",
            " [ 6.40591315e-02 -6.48429593e-03 -9.73860741e-03  9.19712928e-02\n",
            "   7.73243122e-02 -8.98629723e-02  8.73023490e-02  6.12755464e-02\n",
            "   9.24992636e-02  2.07066943e-02]\n",
            " [-9.25260182e-02 -6.80869812e-02  2.60048800e-01 -1.74025454e-01\n",
            "  -4.51148361e-01  2.12255921e-01 -1.89079690e-01 -3.45740146e-01\n",
            "  -5.06357082e-01 -4.23951098e-01]\n",
            " [ 2.35134693e-01  1.24125608e-01 -2.93469062e-01 -2.92154155e-01\n",
            "  -4.40568560e-01  1.46254974e-01 -4.33978699e-01  1.46039054e-01\n",
            "  -2.52308274e-01 -5.49781926e-01]\n",
            " [-8.18348325e-03 -2.38935162e-02 -3.80130124e-02  7.50027636e-02\n",
            "   2.57566505e-02  7.56276882e-02  6.12423261e-02  2.38936288e-02\n",
            "  -9.81565177e-02 -3.37777850e-02]\n",
            " [-6.50461291e-01 -6.75192774e-02 -6.26086773e-01 -1.73054547e-01\n",
            "  -1.07711473e-01 -3.25127700e-02 -6.12503906e-01  1.11928391e-01\n",
            "   1.81676530e-02 -1.80337036e-02]\n",
            " [-2.64581331e-01 -4.05007172e-01 -7.00256120e-01 -8.49935502e-02\n",
            "   1.85527823e-01  4.47225390e-02  1.10891080e-01 -1.69913532e-02\n",
            "  -4.47433073e-01 -1.83142642e-01]\n",
            " [-5.30434022e-01  3.23727500e-02  8.06833702e-02 -1.69223059e-01\n",
            "  -6.41180098e-01 -8.16992346e-02  5.30819411e-02 -1.50673879e-02\n",
            "  -5.98272849e-01 -5.19744636e-01]\n",
            " [ 3.91242908e-02  6.62669098e-02 -5.79702366e-02  6.20884271e-02\n",
            "  -6.79681380e-02  8.48753832e-02 -1.45355828e-02  8.50714950e-02\n",
            "   3.32805769e-02 -5.92600484e-02]\n",
            " [ 1.08613876e-01 -5.66697562e-01 -3.25001786e-01 -2.17002077e-01\n",
            "  -4.69398162e-01  7.14575566e-02  3.88089045e-02 -5.03600088e-01\n",
            "   7.55838938e-04 -4.07934120e-01]\n",
            " [ 5.32794697e-03  7.13197675e-02  3.44077144e-02  8.11967142e-03\n",
            "   2.64488171e-02  6.85397589e-02  8.92122712e-03 -3.08616137e-02\n",
            "  -1.01248544e-02 -4.75690738e-02]\n",
            " [-5.09794865e-01  1.59723727e-01 -5.00570244e-01 -4.73832157e-01\n",
            "  -2.05000383e-02 -5.63938533e-01  1.67240625e-01 -1.99666915e-01\n",
            "  -2.95958541e-01  1.92235186e-01]\n",
            " [-7.05398393e-02 -7.11139686e-01 -2.59551285e-01 -2.77687418e-03\n",
            "  -6.42485329e-01  6.30307875e-02 -3.56882616e-01 -3.05203882e-02\n",
            "   1.60744692e-02 -6.35067638e-04]\n",
            " [-2.12715850e-01  3.65685817e-01 -4.70317219e-01  3.35415341e-01\n",
            "   5.57863064e-02 -3.50396352e-01 -2.46826749e-01 -1.51479922e-01\n",
            "  -4.51995447e-01 -3.13060630e-01]\n",
            " [-2.36023488e-01  5.51856327e-01 -4.56540189e-01 -4.45216533e-01\n",
            "  -5.21968621e-01 -4.24634367e-01 -3.35668279e-01 -3.25585831e-01\n",
            "  -2.96445257e-01  6.81354529e-01]\n",
            " [ 8.21699558e-02 -4.77817995e-02  7.02070415e-02 -4.23973415e-02\n",
            "  -1.02309475e-01 -7.12187106e-01 -4.56872525e-01 -1.47414657e-01\n",
            "   5.69134035e-02 -8.51946842e-02]\n",
            " [-1.26294915e-01  7.63067229e-02 -1.89351847e-01  1.80803378e-01\n",
            "  -3.97738075e-01  9.46984955e-02 -4.58308079e-01 -5.75274909e-01\n",
            "  -3.52880586e-01 -4.94756188e-01]\n",
            " [-4.82681706e-01 -2.08092124e-01 -6.57517134e-01 -5.35510804e-01\n",
            "   3.22461489e-02 -5.72625695e-03 -5.94092931e-01  5.26530400e-04\n",
            "   5.25803901e-03  4.82837434e-03]\n",
            " [-1.58641722e-02 -5.51469028e-01  1.40943810e-02 -5.88210906e-01\n",
            "   1.06418912e-01  6.73238194e-02 -6.59220430e-01 -8.99057181e-02\n",
            "   9.68071419e-02 -1.09050286e-01]\n",
            " [-3.70379000e-01  2.93114415e-01  1.18178974e-01 -5.21637937e-01\n",
            "   1.59291568e-01 -1.02404659e-01 -5.52525091e-01 -3.22148997e-01\n",
            "  -5.81271604e-02 -4.77871668e-01]\n",
            " [-5.77702986e-01 -4.89972591e-01 -2.43800496e-01  1.43533212e-02\n",
            "   6.02208218e-02 -6.80219881e-01 -1.36660430e-01 -4.49230815e-03\n",
            "  -8.75700079e-02  1.38881626e-02]\n",
            " [-6.01735463e-01 -2.25103593e-01 -8.05737201e-01  1.38099031e-01\n",
            "   1.55004180e-01 -4.86935630e-02 -1.15256243e-01 -5.47305494e-01\n",
            "   1.62025581e-02 -2.55619875e-03]\n",
            " [ 3.99048868e-02 -6.99421991e-01 -9.64235877e-02 -1.38393774e-02\n",
            "  -2.70054999e-01 -7.86593686e-03 -5.04433635e-01 -2.21048783e-02\n",
            "  -1.19471693e-01  4.76315488e-02]\n",
            " [ 3.30425002e-01 -7.50085435e-02 -3.08403229e-01 -1.57159837e-01\n",
            "  -1.75419208e-01 -3.31250037e-01 -8.36248301e-02  2.86184392e-01\n",
            "  -1.81239731e-01 -1.96509561e-01]\n",
            " [-5.95737040e-01  5.31390422e-02 -2.19811776e-01 -5.09879661e-01\n",
            "  -4.29545742e-02  1.33412369e-01  8.53557995e-02 -4.31163951e-01\n",
            "   7.09597736e-02 -5.26753582e-01]\n",
            " [-3.49023810e-01 -2.78501889e-01  1.98960914e-03 -3.12549126e-01\n",
            "   2.06311009e-01 -1.46565654e-01 -2.39436204e-01  3.70138376e-01\n",
            "  -4.59768241e-01 -4.11075644e-01]\n",
            " [ 9.94298021e-02 -4.98514403e-01 -6.35566684e-01 -5.31867952e-01\n",
            "  -7.76549321e-02 -2.97941091e-01 -4.96248172e-01  4.78845927e-02\n",
            "  -5.50585139e-01  4.63691016e-02]\n",
            " [ 3.28795449e-01 -1.50200618e-01 -2.94534007e-01 -2.31983587e-01\n",
            "  -1.35256870e-01 -3.60364110e-01 -2.34994518e-01  3.96746651e-01\n",
            "  -2.51217562e-01 -3.14574477e-01]\n",
            " [-4.94455542e-02  8.23125769e-02  4.52831025e-02  8.66527282e-02\n",
            "   5.37256861e-02  6.36613369e-02 -3.30849555e-02 -4.27606095e-02\n",
            "  -6.05432363e-02 -1.40378336e-03]\n",
            " [ 9.15974894e-02  6.18631949e-02  7.44255548e-03 -9.04992107e-03\n",
            "   8.98821455e-02  8.34368304e-02 -4.19034064e-04  6.15103805e-03\n",
            "   6.33761048e-02  8.77770619e-02]\n",
            " [ 1.02494635e-01  7.09042459e-02 -2.97172189e-03 -1.10754953e-02\n",
            "  -1.01930596e-01  1.81696595e-02 -4.56646975e-02  6.13911934e-02\n",
            "  -4.34832285e-02  5.15860771e-02]\n",
            " [-5.08913792e-01 -1.96177087e-01  1.33857910e-01 -1.33112269e-01\n",
            "  -4.28450981e-01 -5.17879480e-01 -5.00700666e-01  2.87386735e-01\n",
            "  -6.59262350e-01 -1.98344844e-03]\n",
            " [ 1.55192257e-01 -3.86479581e-01  7.58031940e-02 -4.63102555e-01\n",
            "  -3.99709783e-01 -9.72972255e-02  7.63469152e-02 -3.61717662e-01\n",
            "  -3.03424870e-01 -3.52325390e-03]\n",
            " [-1.78812282e-01  2.01756305e-02  1.01142651e-01 -2.09274565e-01\n",
            "  -6.19838719e-01 -2.89862428e-01 -4.84697961e-02  1.31189260e-01\n",
            "  -4.88022975e-01 -4.98464363e-01]\n",
            " [ 1.95716068e-01 -4.07452591e-01  4.09054580e-01 -2.48546095e-01\n",
            "  -3.51302976e-01 -4.56389752e-01 -2.99178496e-01 -4.87614047e-01\n",
            "  -5.12757082e-01 -3.35647897e-01]\n",
            " [-2.43069870e-02  7.67870594e-02 -1.20054359e-03  2.62551406e-02\n",
            "  -1.71131068e-02  5.13126864e-02  7.97351729e-03  9.25183160e-02\n",
            "  -1.55552494e-02  6.14830891e-02]\n",
            " [-3.64617354e-01 -3.97638183e-01  3.87863551e-02 -4.73063387e-01\n",
            "   3.16278318e-02 -5.37608187e-01  6.17739275e-02  1.96791700e-03\n",
            "  -6.92636971e-01  1.41026029e-02]\n",
            " [-2.38636066e-01 -1.49711013e-01 -3.26204160e-01 -1.42637723e-01\n",
            "  -4.69783596e-01  6.36249701e-01 -3.72927088e-01  6.87504093e-02\n",
            "  -3.82723510e-01 -2.26360753e-01]\n",
            " [ 1.66645547e-01  9.64632016e-03  1.05169621e-01 -2.78273882e-01\n",
            "  -4.45991304e-01 -5.65308851e-02 -5.89465392e-01 -4.77176580e-02\n",
            "  -1.35406183e-01 -5.31584268e-01]\n",
            " [-3.12390791e-01  5.94131942e-02 -1.35501612e-01  1.39675970e-01\n",
            "  -3.99081719e-01 -1.87488165e-01 -3.33854816e-01 -3.81067202e-01\n",
            "   1.46332801e-01 -5.21598063e-01]\n",
            " [-7.49565161e-02 -5.61991999e-03 -3.95027794e-01  1.97758949e-01\n",
            "  -3.63066596e-01 -7.03185341e-04 -3.54604805e-01  6.56340489e-02\n",
            "  -4.48849503e-01 -5.56716359e-01]\n",
            " [-4.81540567e-02 -2.27581831e-01  5.34532129e-02  4.76792541e-01\n",
            "  -1.87201994e-01 -4.70493085e-01 -2.61844887e-01 -3.41342389e-01\n",
            "  -3.38289616e-01 -1.51482961e-01]\n",
            " [-1.75277556e-01 -2.69732995e-01 -5.36246238e-01  9.98249913e-02\n",
            "  -5.91088143e-01  1.11503426e-01 -4.77911841e-01  1.12653488e-01\n",
            "  -4.13312941e-01 -4.93953326e-02]\n",
            " [ 6.41110653e-01 -1.27525233e-01 -1.80267619e-01 -1.96447125e-01\n",
            "  -1.63020561e-01 -4.85848945e-01 -2.61646154e-01 -3.02184951e-01\n",
            "  -2.51518620e-01 -2.10071478e-01]\n",
            " [ 1.13664522e-02  9.59886681e-02  9.84173436e-02  7.29596209e-02\n",
            "  -2.33508936e-02  4.82863892e-02  2.58974540e-02 -2.27271543e-02\n",
            "  -1.01659201e-01  8.97001144e-02]\n",
            " [-2.84185020e-01 -1.41557057e-01 -1.86347604e-01 -1.86584715e-01\n",
            "  -9.23607041e-02 -2.82705278e-01 -1.53634773e-01  6.51719208e-01\n",
            "  -2.95906384e-01 -3.52790416e-01]\n",
            " [ 2.33746469e-01 -3.44977578e-01 -4.48644314e-01 -3.78443634e-01\n",
            "   5.68701241e-02 -2.64265543e-01  2.24823775e-03  6.35697180e-02\n",
            "  -4.34157590e-01 -3.86073789e-01]\n",
            " [ 2.40274619e-01 -3.66046674e-01 -3.60460642e-01  1.90284862e-01\n",
            "  -5.08211586e-01 -1.55069110e-01 -2.50592472e-01 -3.41483062e-01\n",
            "  -5.87514735e-01 -1.38985899e-01]\n",
            " [-1.68471602e-01 -5.73835036e-02 -3.77285820e-02  5.16287223e-02\n",
            "  -1.40842396e-01 -1.14290781e-01  3.37449415e-02  4.10865646e-01\n",
            "  -9.97346252e-02 -3.02401532e-01]\n",
            " [-4.37363599e-01 -3.49552181e-01  6.69439364e-02 -2.49720161e-01\n",
            "   5.79529901e-02 -4.51869490e-01  5.49279877e-02 -4.54297494e-01\n",
            "   1.90715292e-01 -2.51477104e-01]\n",
            " [ 2.56778011e-02  3.81477824e-02  1.74768688e-02  9.42175657e-02\n",
            "   9.59527725e-02  4.33875237e-02 -6.87337968e-02 -5.93824698e-02\n",
            "  -5.02706014e-02 -4.57003143e-02]\n",
            " [-2.38090612e-01 -5.31678120e-01 -2.28126796e-01 -2.20608948e-01\n",
            "  -4.55159004e-03 -4.33212240e-02 -7.37443918e-01  9.63818145e-03\n",
            "   7.61433997e-02  1.59883619e-02]\n",
            " [ 3.07916893e-02 -3.30581426e-02 -2.61812177e-02  2.46263998e-02\n",
            "  -6.56182519e-01 -8.21646883e-02 -6.26139931e-01 -9.00656868e-02\n",
            "   2.77305118e-02 -3.15933272e-01]\n",
            " [-4.09027770e-02 -6.80370247e-01 -1.21754136e-01 -6.28928879e-01\n",
            "   1.89883984e-02 -1.19890469e-01  1.28159469e-02 -4.61428672e-02\n",
            "  -4.30971626e-02  1.00559178e-02]\n",
            " [-7.51467608e-02  7.67618925e-03  4.41970528e-02  4.01441540e-02\n",
            "   1.07268980e-01 -8.94974619e-02  4.19711258e-02  6.63970540e-02\n",
            "   2.27435152e-02  5.74504960e-02]\n",
            " [-5.72109109e-01 -2.32029711e-01  9.93643587e-02 -4.43234902e-01\n",
            "   6.74665073e-02 -3.76773207e-01  1.49171278e-01 -2.49158034e-01\n",
            "  -5.66415433e-01 -4.04193129e-01]\n",
            " [-1.44352795e-01  3.22474888e-01 -1.09108270e-01  4.22255001e-02\n",
            "  -1.45787183e-01 -2.55971615e-01 -1.87306266e-01  2.69498822e-01\n",
            "  -2.85111900e-01 -1.95527288e-01]\n",
            " [ 7.11621042e-02  3.52784823e-02 -2.34775670e-02  1.09624960e-02\n",
            "  -9.53215677e-02  5.92744976e-02  6.43506815e-02  3.66111295e-02\n",
            "  -1.19194497e-02  8.46503261e-02]\n",
            " [ 7.91797752e-02  2.00483935e-02 -7.96855197e-02 -6.22227809e-02\n",
            "  -9.30505709e-02  7.90758457e-02  8.28253993e-02  1.01810621e-01\n",
            "  -7.27462843e-02  6.37290110e-02]\n",
            " [ 7.72428611e-02  3.35560595e-02  3.92703567e-02  8.94433179e-02\n",
            "  -2.07579957e-02  9.69703913e-02  1.95475594e-03 -7.34914014e-02\n",
            "   8.28068609e-02  4.74925125e-02]\n",
            " [-3.58849435e-01 -2.79578632e-01  6.28458788e-02  2.58447668e-01\n",
            "  -1.26771564e-01  1.02108171e-01 -5.32158187e-01 -4.97428991e-01\n",
            "  -3.89796782e-01 -4.49083982e-01]\n",
            " [ 8.38174135e-02  7.22209811e-02 -1.32409612e-02 -1.13266938e-02\n",
            "   7.55743510e-02 -1.70449953e-03 -6.24962302e-02  9.79469208e-03\n",
            "   7.36404459e-02 -4.83475828e-02]\n",
            " [-4.97429323e-01  1.32792965e-01 -5.08534878e-01 -4.06381218e-01\n",
            "  -3.81432215e-01 -4.69048467e-01 -5.57066212e-01  9.26581039e-02\n",
            "   2.24235417e-01  1.30393831e-01]\n",
            " [-7.64558569e-02  7.16826464e-02  4.19092036e-02  7.48349902e-02\n",
            "   3.73247168e-02  6.84882935e-02  6.36365445e-02  4.65930333e-02\n",
            "  -4.79964084e-03  2.48615163e-02]\n",
            " [-5.10480220e-01  4.77354209e-02  1.04372502e-01 -1.48145889e-01\n",
            "  -5.91703534e-01  6.17419113e-03 -1.60190407e-01 -4.01029867e-01\n",
            "   1.39205481e-01 -3.82121980e-01]\n",
            " [-5.77108135e-02  1.38315646e-02  3.60480575e-01 -8.87268323e-02\n",
            "   1.64087507e-01 -1.35686175e-01 -2.06358015e-01 -1.72521672e-01\n",
            "  -2.25789425e-01 -1.80325103e-01]\n",
            " [-3.10978701e-02  4.27984066e-02 -7.76220850e-02  3.84062530e-01\n",
            "   1.51986035e-01 -2.22030933e-01 -1.58821011e-01 -1.14083695e-01\n",
            "  -2.73017124e-01 -1.09446802e-01]\n",
            " [-7.62026861e-02  4.47486932e-01 -1.91313253e-01 -3.12893759e-01\n",
            "  -2.14046223e-01 -1.99114701e-01 -2.34680024e-01  4.14789205e-03\n",
            "  -4.56096245e-01 -3.44992381e-01]\n",
            " [-1.74828187e-01  3.88174018e-01 -2.23065497e-01 -3.43953190e-01\n",
            "  -2.77369501e-01 -1.09650490e-01 -1.19907334e-01  2.03930991e-01\n",
            "  -3.93644396e-01 -9.60733813e-02]\n",
            " [ 5.97638481e-02 -2.30354485e-01 -3.71092392e-01 -2.34929558e-01\n",
            "  -3.40080960e-01  5.32181587e-01 -2.27960758e-01 -2.85590568e-01\n",
            "  -5.26531877e-01 -2.82367826e-01]\n",
            " [-4.14589242e-01  1.16886724e-02  2.73213197e-02 -2.57252226e-01\n",
            "   2.39393465e-01 -1.31232260e-01 -4.88995276e-01 -4.23488168e-01\n",
            "  -5.71245543e-01  8.80775408e-02]\n",
            " [-4.92626515e-01 -3.44597869e-01  3.39276594e-02  5.40469649e-02\n",
            "   2.06383697e-02 -6.31548630e-01 -1.22416161e-01 -2.93130169e-01\n",
            "  -4.33237279e-01  1.16845296e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo1RGc8r6srZ"
      },
      "source": [
        "## **Let's Test our trained model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GXXTT7fwF2Bh",
        "outputId": "3c84a904-2c56-4fdf-fb28-8e129a0d5f47"
      },
      "source": [
        "plt.imshow(test_images[10].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDXs9HGDGmD5",
        "outputId": "8968fd59-28fb-462c-a0f6-75157cef95ce"
      },
      "source": [
        "output = predict(test_images[10],weights_0_1,weights_1_2)\n",
        "print(\"predicted label: \",np.argmax(output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label:  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVnUyjGJApBa"
      },
      "source": [
        "## **Same code in Tensorflow keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LLD3eDYAvEt",
        "outputId": "c01ab1bf-6339-4359-d1ed-7d812266f92a"
      },
      "source": [
        "import keras\n",
        "from keras.engine import InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(hidden_neurons, activation='relu'))\n",
        "model.add(Dense(output_neruons, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "model.fit(images, labels, batch_size=batch_size, epochs=iterations, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 29ms/step - loss: 2.3807 - accuracy: 0.1028 - val_loss: 2.2826 - val_accuracy: 0.1300\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.2582 - accuracy: 0.1465 - val_loss: 2.1924 - val_accuracy: 0.1800\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.1738 - accuracy: 0.2073 - val_loss: 2.1168 - val_accuracy: 0.2450\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1013 - accuracy: 0.2802 - val_loss: 2.0486 - val_accuracy: 0.3450\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0365 - accuracy: 0.3819 - val_loss: 1.9850 - val_accuracy: 0.3950\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9795 - accuracy: 0.4436 - val_loss: 1.9247 - val_accuracy: 0.4650\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9210 - accuracy: 0.4940 - val_loss: 1.8660 - val_accuracy: 0.5200\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8759 - accuracy: 0.5360 - val_loss: 1.8082 - val_accuracy: 0.5750\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8145 - accuracy: 0.5384 - val_loss: 1.7527 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7619 - accuracy: 0.6036 - val_loss: 1.6990 - val_accuracy: 0.6200\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7053 - accuracy: 0.6286 - val_loss: 1.6466 - val_accuracy: 0.6450\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6613 - accuracy: 0.6149 - val_loss: 1.5966 - val_accuracy: 0.6550\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6105 - accuracy: 0.6524 - val_loss: 1.5480 - val_accuracy: 0.6600\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5529 - accuracy: 0.6796 - val_loss: 1.5024 - val_accuracy: 0.6800\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5110 - accuracy: 0.6986 - val_loss: 1.4579 - val_accuracy: 0.6900\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4752 - accuracy: 0.7072 - val_loss: 1.4160 - val_accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4130 - accuracy: 0.7361 - val_loss: 1.3762 - val_accuracy: 0.7050\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3816 - accuracy: 0.7396 - val_loss: 1.3388 - val_accuracy: 0.7200\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3396 - accuracy: 0.7458 - val_loss: 1.3022 - val_accuracy: 0.7250\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3090 - accuracy: 0.7561 - val_loss: 1.2684 - val_accuracy: 0.7300\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2957 - accuracy: 0.7404 - val_loss: 1.2365 - val_accuracy: 0.7450\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2478 - accuracy: 0.7713 - val_loss: 1.2057 - val_accuracy: 0.7450\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2492 - accuracy: 0.7461 - val_loss: 1.1760 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2095 - accuracy: 0.7451 - val_loss: 1.1475 - val_accuracy: 0.7600\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1667 - accuracy: 0.7697 - val_loss: 1.1207 - val_accuracy: 0.7700\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1288 - accuracy: 0.7789 - val_loss: 1.0955 - val_accuracy: 0.7900\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1286 - accuracy: 0.7797 - val_loss: 1.0714 - val_accuracy: 0.7950\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0868 - accuracy: 0.7906 - val_loss: 1.0485 - val_accuracy: 0.8050\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0481 - accuracy: 0.7913 - val_loss: 1.0266 - val_accuracy: 0.8050\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0193 - accuracy: 0.7985 - val_loss: 1.0065 - val_accuracy: 0.8150\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.0112 - accuracy: 0.7966 - val_loss: 0.9871 - val_accuracy: 0.8100\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9733 - accuracy: 0.8166 - val_loss: 0.9684 - val_accuracy: 0.8150\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9717 - accuracy: 0.8065 - val_loss: 0.9512 - val_accuracy: 0.8200\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9548 - accuracy: 0.8070 - val_loss: 0.9338 - val_accuracy: 0.8250\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9368 - accuracy: 0.8231 - val_loss: 0.9179 - val_accuracy: 0.8250\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9225 - accuracy: 0.8221 - val_loss: 0.9025 - val_accuracy: 0.8250\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9134 - accuracy: 0.8208 - val_loss: 0.8876 - val_accuracy: 0.8300\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8634 - accuracy: 0.8365 - val_loss: 0.8736 - val_accuracy: 0.8300\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8728 - accuracy: 0.8308 - val_loss: 0.8609 - val_accuracy: 0.8300\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8206 - accuracy: 0.8491 - val_loss: 0.8486 - val_accuracy: 0.8250\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8396 - accuracy: 0.8227 - val_loss: 0.8364 - val_accuracy: 0.8250\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8300 - accuracy: 0.8191 - val_loss: 0.8247 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8008 - accuracy: 0.8568 - val_loss: 0.8140 - val_accuracy: 0.8250\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7814 - accuracy: 0.8441 - val_loss: 0.8031 - val_accuracy: 0.8250\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7799 - accuracy: 0.8450 - val_loss: 0.7927 - val_accuracy: 0.8250\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7614 - accuracy: 0.8612 - val_loss: 0.7835 - val_accuracy: 0.8250\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7681 - accuracy: 0.8401 - val_loss: 0.7741 - val_accuracy: 0.8250\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7483 - accuracy: 0.8644 - val_loss: 0.7652 - val_accuracy: 0.8250\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7423 - accuracy: 0.8472 - val_loss: 0.7571 - val_accuracy: 0.8250\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7060 - accuracy: 0.8669 - val_loss: 0.7489 - val_accuracy: 0.8250\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7143 - accuracy: 0.8557 - val_loss: 0.7408 - val_accuracy: 0.8250\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7154 - accuracy: 0.8588 - val_loss: 0.7333 - val_accuracy: 0.8250\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.8737 - val_loss: 0.7262 - val_accuracy: 0.8250\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.8674 - val_loss: 0.7193 - val_accuracy: 0.8250\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7140 - accuracy: 0.8571 - val_loss: 0.7129 - val_accuracy: 0.8250\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6804 - accuracy: 0.8689 - val_loss: 0.7065 - val_accuracy: 0.8250\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6609 - accuracy: 0.8773 - val_loss: 0.7004 - val_accuracy: 0.8250\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.8822 - val_loss: 0.6944 - val_accuracy: 0.8250\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.8705 - val_loss: 0.6881 - val_accuracy: 0.8300\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6372 - accuracy: 0.8821 - val_loss: 0.6829 - val_accuracy: 0.8300\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.8822 - val_loss: 0.6780 - val_accuracy: 0.8300\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6376 - accuracy: 0.8696 - val_loss: 0.6724 - val_accuracy: 0.8300\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6241 - accuracy: 0.8909 - val_loss: 0.6671 - val_accuracy: 0.8300\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.8798 - val_loss: 0.6621 - val_accuracy: 0.8300\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6148 - accuracy: 0.8771 - val_loss: 0.6577 - val_accuracy: 0.8300\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5849 - accuracy: 0.8821 - val_loss: 0.6525 - val_accuracy: 0.8350\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.8708 - val_loss: 0.6481 - val_accuracy: 0.8350\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6012 - accuracy: 0.8766 - val_loss: 0.6445 - val_accuracy: 0.8350\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5897 - accuracy: 0.8851 - val_loss: 0.6403 - val_accuracy: 0.8350\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.8928 - val_loss: 0.6362 - val_accuracy: 0.8350\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5722 - accuracy: 0.8931 - val_loss: 0.6321 - val_accuracy: 0.8350\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5531 - accuracy: 0.8929 - val_loss: 0.6286 - val_accuracy: 0.8350\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5305 - accuracy: 0.8948 - val_loss: 0.6251 - val_accuracy: 0.8400\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5626 - accuracy: 0.8816 - val_loss: 0.6211 - val_accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.8888 - val_loss: 0.6175 - val_accuracy: 0.8450\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5450 - accuracy: 0.8968 - val_loss: 0.6138 - val_accuracy: 0.8500\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5229 - accuracy: 0.8996 - val_loss: 0.6110 - val_accuracy: 0.8500\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5563 - accuracy: 0.8909 - val_loss: 0.6078 - val_accuracy: 0.8500\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.8939 - val_loss: 0.6045 - val_accuracy: 0.8500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5305 - accuracy: 0.8960 - val_loss: 0.6016 - val_accuracy: 0.8500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4939 - accuracy: 0.9069 - val_loss: 0.5994 - val_accuracy: 0.8500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5394 - accuracy: 0.8925 - val_loss: 0.5967 - val_accuracy: 0.8500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4857 - accuracy: 0.9050 - val_loss: 0.5944 - val_accuracy: 0.8450\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.9022 - val_loss: 0.5913 - val_accuracy: 0.8450\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4799 - accuracy: 0.9055 - val_loss: 0.5882 - val_accuracy: 0.8450\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5145 - accuracy: 0.8974 - val_loss: 0.5862 - val_accuracy: 0.8450\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5176 - accuracy: 0.8995 - val_loss: 0.5836 - val_accuracy: 0.8450\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5033 - accuracy: 0.8988 - val_loss: 0.5807 - val_accuracy: 0.8450\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4861 - accuracy: 0.9098 - val_loss: 0.5784 - val_accuracy: 0.8500\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5099 - accuracy: 0.8909 - val_loss: 0.5762 - val_accuracy: 0.8500\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 0.9035 - val_loss: 0.5737 - val_accuracy: 0.8500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4841 - accuracy: 0.9047 - val_loss: 0.5719 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.9108 - val_loss: 0.5694 - val_accuracy: 0.8500\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.8952 - val_loss: 0.5673 - val_accuracy: 0.8500\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4586 - accuracy: 0.9085 - val_loss: 0.5649 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4396 - accuracy: 0.9112 - val_loss: 0.5633 - val_accuracy: 0.8500\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4710 - accuracy: 0.8996 - val_loss: 0.5613 - val_accuracy: 0.8500\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4379 - accuracy: 0.9147 - val_loss: 0.5590 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4664 - accuracy: 0.9111 - val_loss: 0.5570 - val_accuracy: 0.8500\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.9092 - val_loss: 0.5553 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3655e1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}